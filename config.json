{
  "data_dir": "data",
  "batch_size": 32,
  "max_len": 100,
  "word2vec_file": "data/word2vec.txt",
  "embedding_dim": 100,
  "hidden_dim": 256,
  "output_dim": 3,
  "num_layers": 2,
  "dropout": 0.5,
  "learning_rate": 0.001,
  "epochs": 10,
  "checkpoint_dir": "checkpoints",
  "model_name": "attention"
}